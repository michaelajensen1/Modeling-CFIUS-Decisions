{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4be9c9a",
   "metadata": {},
   "source": [
    "# Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af747ae7",
   "metadata": {},
   "source": [
    "## Package Imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0a0ab1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964343af",
   "metadata": {},
   "source": [
    "## Control Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "45b9eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weight = {0:9, 1:1} #An alternative, we could use 'balanced' or 'balanced_subsample'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ecedfb",
   "metadata": {},
   "source": [
    "## Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2969e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_excel(r'Regression_Analysis_Sheet_(Imputation_and_All_Features_Tradewar).xlsx')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df12d1de",
   "metadata": {},
   "source": [
    "## Merging Similar Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f35165a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "all_data['Communications'] = all_data['Communications'] + all_data['Communication Services']\n",
    "all_data.drop('Communication Services', axis=1, inplace=True)\n",
    "\n",
    "all_data['Consumer'] = (all_data['Consumer Discretionary'] + \n",
    "                        all_data['Consumer, Cyclical'] + \n",
    "                        all_data['Consumer, Cyclical, Financial, Industrial'] +\n",
    "                        all_data['Consumer, Non-cyclical'] +\n",
    "                        all_data['Consumer, Non-cyclical, Industrial'])\n",
    "\n",
    "all_data.drop(['Consumer Discretionary',\n",
    "               'Consumer, Cyclical',\n",
    "               'Consumer, Cyclical, Financial, Industrial',\n",
    "               'Consumer, Non-cyclical',\n",
    "               'Consumer, Non-cyclical, Industrial'],\n",
    "                axis=1, inplace=True\n",
    "             )\n",
    "\n",
    "all_data['Industrials'] = all_data['Industrials'] + all_data['Industrial']\n",
    "all_data.drop('Industrial', axis=1, inplace=True)\n",
    "\n",
    "all_data['Technology'] = all_data['Technology'] + all_data['Information Technology']\n",
    "all_data.drop('Information Technology', axis=1, inplace=True)\n",
    "\n",
    "all_data['Financial'] = all_data['Financial'] + all_data['Financials']\n",
    "all_data.drop('Financials', axis=1, inplace=True)\n",
    "\n",
    "all_data['Materials'] = all_data['Materials'] + all_data['Material']\n",
    "all_data.drop('Material', axis=1, inplace=True)\n",
    "\n",
    "all_data['Energy and Utilities'] = all_data['Energy'] + all_data['Utilities']\n",
    "all_data.drop(['Energy', 'Utilities'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c615df4",
   "metadata": {},
   "source": [
    "## Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c4020adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data.drop('Outcome Variable:', axis=1)\n",
    "Y = all_data['Outcome Variable:']\n",
    "\n",
    "x_train, x_test, y_train, y_test = \\\n",
    "train_test_split(X, Y, test_size=0.2, stratify = Y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123c297a",
   "metadata": {},
   "source": [
    "## Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "987ebbcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train, columns = X.columns)\n",
    "\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test, columns = X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82681ca",
   "metadata": {},
   "source": [
    "# Searching for Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3f6d4f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "{'n_estimators': 200, 'max_features': 'sqrt', 'max_depth': None}\n"
     ]
    }
   ],
   "source": [
    "# Defining search parameters\n",
    "rfc = RandomForestClassifier(class_weight = class_weight, random_state=42)\n",
    "n_estimators = \\\n",
    "[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)] # number of trees in random forest\n",
    "\n",
    "max_features = ['auto', 'sqrt'] # number of features at every split\n",
    "\n",
    "max_depth = [int(x) for x in np.linspace(100, 500, num = 11)] # max depth\n",
    "max_depth.append(None)\n",
    "\n",
    "# Creating random grid\n",
    "random_grid = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " 'max_depth': max_depth\n",
    "}\n",
    "\n",
    "# Random search of parameters\n",
    "rfc_grid = RandomizedSearchCV(estimator = rfc, \n",
    "                              param_distributions = random_grid,\n",
    "                              n_iter = 100,\n",
    "                              cv = 3,\n",
    "                              verbose=2,\n",
    "                              random_state=42,\n",
    "                              n_jobs = -1)\n",
    "# Fit the model\n",
    "rfc_grid.fit(x_train, y_train)\n",
    "\n",
    "# Printing results\n",
    "print(rfc_grid.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cbc4ad",
   "metadata": {},
   "source": [
    "# Refitting Model with Optimal Hyperparameters to Find Most Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3241984a",
   "metadata": {},
   "source": [
    "## Refitting With Optimal Hpyerparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d9f1576",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimal Confusion Matrix ===\n",
      "[[ 0  5]\n",
      " [ 1 41]]\n",
      "\n",
      "\n",
      "=== Optimal Classification Report ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.89      0.98      0.93        42\n",
      "\n",
      "    accuracy                           0.87        47\n",
      "   macro avg       0.45      0.49      0.47        47\n",
      "weighted avg       0.80      0.87      0.83        47\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores for Optimal RFC ===\n",
      "[0.73015873 0.38888889 0.49206349 0.65079365 0.88095238 0.76190476\n",
      " 0.33333333 0.52380952 0.66666667 0.60833333]\n",
      "\n",
      "\n",
      "=== Mean AUC Score for Optimal RFC ===\n",
      "Mean AUC Score - Random Forest:  0.6036904761904762\n"
     ]
    }
   ],
   "source": [
    "rfc_optimal = RandomForestClassifier(n_estimators=rfc_grid.best_params_['n_estimators'],\n",
    "                                     class_weight = class_weight,\n",
    "                                     max_depth=rfc_grid.best_params_['max_depth'],\n",
    "                                     max_features=rfc_grid.best_params_['max_features'],\n",
    "                                     random_state=42)\n",
    "rfc_optimal.fit(x_train,y_train)\n",
    "rfc_optimal_predict = rfc_optimal.predict(x_test)\n",
    "rfc_optimal_cv_score = cross_val_score(rfc_optimal,\n",
    "                                       X,\n",
    "                                       Y,\n",
    "                                       cv=10,\n",
    "                                       scoring='roc_auc')\n",
    "\n",
    "print(\"=== Optimal Confusion Matrix ===\")\n",
    "print(confusion_matrix(y_test, rfc_optimal_predict))\n",
    "print('\\n')\n",
    "print(\"=== Optimal Classification Report ===\")\n",
    "print(classification_report(y_test, rfc_optimal_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores for Optimal RFC ===\")\n",
    "print(rfc_optimal_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score for Optimal RFC ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_optimal_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb43cfa",
   "metadata": {},
   "source": [
    "## Printing Important Features and Selecting Top 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "180306fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Variable:                0.226415\n",
      "IPR:                           0.148622\n",
      "Esp:                           0.076864\n",
      "Industrials                    0.047845\n",
      "Stock                          0.038019\n",
      "china                          0.035679\n",
      "Cash                           0.033500\n",
      "Technology                     0.032931\n",
      "hong kong                      0.031272\n",
      "Consumer                       0.031112\n",
      "Communications                 0.026936\n",
      "Energy and Utilities           0.022670\n",
      "Voluntary Offer Agreements     0.022617\n",
      "Tradewar Variable:             0.021524\n",
      "united kingdom                 0.019833\n",
      "Undisclosed                    0.018782\n",
      "Comprehensive safeguards       0.018471\n",
      "Financial                      0.017555\n",
      "canada                         0.016964\n",
      "france                         0.016126\n",
      "Materials                      0.014191\n",
      "Basic Materials                0.011217\n",
      "japan                          0.010529\n",
      "luxembourg                     0.009821\n",
      "Cash and Stock                 0.009519\n",
      "germany                        0.007354\n",
      "finland                        0.006166\n",
      "sweden                         0.004104\n",
      "switzerland                    0.004061\n",
      "singapore                      0.003268\n",
      "australia                      0.002753\n",
      "south korea                    0.002610\n",
      "Real Estate                    0.002403\n",
      "INFCIRC/66/Rev.2 Agreements    0.001694\n",
      "netherlands                    0.001594\n",
      "india                          0.001097\n",
      "taiwan                         0.000929\n",
      "italy                          0.000752\n",
      "israel                         0.000681\n",
      "denmark                        0.000464\n",
      "Cash or Stock                  0.000420\n",
      "belgium                        0.000335\n",
      "Private                        0.000166\n",
      "south africa                   0.000139\n",
      "bermuda                        0.000000\n",
      "Health Care                    0.000000\n",
      "spain                          0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "feature_importance = pd.Series(rfc_optimal.feature_importances_,\n",
    "                               index=X.columns.values).sort_values(ascending=False)\n",
    "print(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1d50fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Value Variable:', 'IPR:', 'Esp:', 'Industrials', 'Stock']\n"
     ]
    }
   ],
   "source": [
    "container = feature_importance[:5].axes\n",
    "new_model_columns = []\n",
    "for i in range(5):\n",
    "    new_model_columns.append(container[0][i])\n",
    "print(new_model_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc417d3",
   "metadata": {},
   "source": [
    "# Re-running Random Forest with Most Important Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f855dc7",
   "metadata": {},
   "source": [
    "## Making New Dataset with Only Top 5 Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97425e58",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Value Variable:  IPR:  Esp:  Industrials  Stock\n",
      "0        91.000000  7.68   0.0            0      0\n",
      "1      1688.810000  8.62   0.4            0      0\n",
      "2      4146.400000  8.20   0.0            1      0\n",
      "3       358.430000  7.68   0.0            0      0\n",
      "4      3667.369452  7.30   0.0            1      0\n"
     ]
    }
   ],
   "source": [
    "top_features_x = all_data[new_model_columns]\n",
    "print(top_features_x.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4224f01f",
   "metadata": {},
   "source": [
    "## Splitting and Scaling New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b6c3214",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(top_features_x,\n",
    "                                                    Y, test_size=0.2, \n",
    "                                                    stratify = Y, \n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "704d2827",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_train = pd.DataFrame(x_train, columns = top_features_x.columns)\n",
    "\n",
    "x_test = scaler.fit_transform(x_test)\n",
    "x_test = pd.DataFrame(x_test, columns = top_features_x.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3097d7e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(rfc_grid.best_params_['max_depth'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da7f85",
   "metadata": {},
   "source": [
    "## Using New Dataset to Find Optimal Hyperparameters (Focused Around Results from Earlier Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5ed0399e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "{'max_depth': None, 'max_features': 'auto', 'n_estimators': 211}\n"
     ]
    }
   ],
   "source": [
    "# Defining search parameters (searching around optimal parameters discovered in random search)\n",
    "rfc = RandomForestClassifier(class_weight = class_weight, random_state=42)\n",
    "n_estimators = [int(x) for x in np.linspace(start = rfc_grid.best_params_['n_estimators'] - 100, \n",
    "                                            stop = rfc_grid.best_params_['n_estimators'] + 100,\n",
    "                                            num = 10)] # number of trees in random forest\n",
    "max_features = ['auto'] # number of features at every split\n",
    "\n",
    "if rfc_grid.best_params_['max_depth'] == None:\n",
    "    max_depth = [rfc_grid.best_params_['max_depth']]\n",
    "else:\n",
    "    max_depth = [int(x) for x in np.linspace(rfc_grid.best_params_['max_depth']-20,\n",
    "                                             rfc_grid.best_params_['max_depth']+20,\n",
    "                                             num = 5)] # max depth\n",
    "# max_depth.append(None)\n",
    "\n",
    "# Creating search grid\n",
    "search_grid = {\n",
    " 'n_estimators': n_estimators,\n",
    " 'max_features': max_features,\n",
    " 'max_depth': max_depth\n",
    "}\n",
    "\n",
    "# Grid search of parameters\n",
    "rfc_grid = GridSearchCV(estimator = rfc,\n",
    "                        param_grid = search_grid,\n",
    "                        cv = 3,\n",
    "                        verbose=2,\n",
    "                        n_jobs = -1)\n",
    "\n",
    "# Fitting the model\n",
    "rfc_grid.fit(x_train, y_train)\n",
    "\n",
    "# Printing results\n",
    "print(rfc_grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9038bc57",
   "metadata": {},
   "source": [
    "## Refitting with Optimal Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "46bc354c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Optimal Confusion Matrix from Focused Featureset ===\n",
      "[[ 0  5]\n",
      " [ 2 40]]\n",
      "\n",
      "\n",
      "=== Optimal Classification Report from Focused Featureset ===\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         5\n",
      "           1       0.89      0.95      0.92        42\n",
      "\n",
      "    accuracy                           0.85        47\n",
      "   macro avg       0.44      0.48      0.46        47\n",
      "weighted avg       0.79      0.85      0.82        47\n",
      "\n",
      "\n",
      "\n",
      "=== All AUC Scores for Optimal RFC from Focused Featureset ===\n",
      "[0.72222222 0.38095238 0.5        0.64285714 0.89285714 0.76190476\n",
      " 0.35714286 0.54761905 0.65       0.60833333]\n",
      "\n",
      "\n",
      "=== Mean AUC Score for Optimal RFC from Focused Featureset ===\n",
      "Mean AUC Score - Random Forest:  0.6063888888888889\n"
     ]
    }
   ],
   "source": [
    "rfc_optimal_focused = RandomForestClassifier(n_estimators=rfc_grid.best_params_['n_estimators'],\n",
    "                                     class_weight = class_weight,\n",
    "                                     max_depth=rfc_grid.best_params_['max_depth'],\n",
    "                                     max_features=rfc_grid.best_params_['max_features'],\n",
    "                                     random_state=42)\n",
    "\n",
    "rfc_optimal_focused.fit(x_train,y_train)\n",
    "rfc_optimal_focused_predict = rfc_optimal_focused.predict(x_test)\n",
    "rfc_optimal_focused_cv_score = cross_val_score(rfc_optimal_focused,\n",
    "                                               X,\n",
    "                                               Y, \n",
    "                                               cv=10,\n",
    "                                               scoring='roc_auc')\n",
    "\n",
    "print(\"=== Optimal Confusion Matrix from Focused Featureset ===\")\n",
    "print(confusion_matrix(y_test, rfc_optimal_focused_predict))\n",
    "print('\\n')\n",
    "print(\"=== Optimal Classification Report from Focused Featureset ===\")\n",
    "print(classification_report(y_test, rfc_optimal_focused_predict))\n",
    "print('\\n')\n",
    "print(\"=== All AUC Scores for Optimal RFC from Focused Featureset ===\")\n",
    "print(rfc_optimal_focused_cv_score)\n",
    "print('\\n')\n",
    "print(\"=== Mean AUC Score for Optimal RFC from Focused Featureset ===\")\n",
    "print(\"Mean AUC Score - Random Forest: \", rfc_optimal_focused_cv_score.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba005ef0",
   "metadata": {},
   "source": [
    "## Printing Final Most Important Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a685e263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Value Variable:    0.410838\n",
      "IPR:               0.306799\n",
      "Esp:               0.148229\n",
      "Stock              0.069532\n",
      "Industrials        0.064603\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_feature_importance = pd.Series(rfc_optimal_focused.feature_importances_,\n",
    "                                     index=top_features_x.columns.values).sort_values(ascending=False)\n",
    "print(final_feature_importance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce704599",
   "metadata": {},
   "source": [
    "# Using Model to Predict Transaction Outcomes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2711c",
   "metadata": {},
   "source": [
    "## Importing Experimental Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1a3e5140",
   "metadata": {},
   "outputs": [],
   "source": [
    "experimental_data = pd.read_excel(r'Experimental_Transactions_(Tradewar_Update).xlsx')\n",
    "experimental_data = experimental_data[new_model_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30e7f159",
   "metadata": {},
   "source": [
    "## Using Test Transactions to Get Predicted Outcome from Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "939fe223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Chinese Transaction (failed in real life). Predicted outcome:  1\n",
      "Same transaction, but China has IPR, Esp, and Nuclear variables of Canada. Predicted outcome:  1\n",
      "Same transaction, but country is Canada instead of China and Canada has China IPR, Esp, and Nuclear variables. Predicted outcome:  1\n",
      "Same transaction, but country is Canada and Canada has its own IPR, Esp, and Nuclear variables. Predicted outcome:  1\n",
      "5. Same as 2., but trade war variable is active (1):  1\n",
      "6. Same as 4., but trade war variable is active (1):  1\n",
      "7. China w/ same IPR and Esp. as used in logistic model; $750M Financial sector transcation:  1\n",
      "8. China w/ same IPR and Esp. as used in logistic model; $400M Materials sector transcation:  1\n",
      "China w/ same IPR and Esp. as used in logistic model; $1000M Financial sector transcationtradewar variable active:  1\n"
     ]
    }
   ],
   "source": [
    "experimental_outcomes = rfc_optimal_focused.predict(experimental_data)\n",
    "\n",
    "#Original Chinese Transaction (blocked in real life)\n",
    "print('Original Chinese Transaction (failed in real life). Predicted outcome: ', \n",
    "      experimental_outcomes[0])\n",
    "\n",
    "#Same transaction, but China has IPR, Esp, and Nuclear variables of Canada\n",
    "print('Same transaction, but China has IPR, Esp, and Nuclear variables of Canada. Predicted outcome: ', \n",
    "      experimental_outcomes[1])\n",
    "\n",
    "#Same transaction, but country is Canada instead of China and Canada has China's IPR, Esp, and Nuclear variables\n",
    "print('Same transaction, but country is Canada instead of China and Canada has China IPR, Esp, and Nuclear variables.\\\n",
    " Predicted outcome: ', \n",
    "      experimental_outcomes[2])\n",
    "\n",
    "#Same transaction, but country is Canada and Canada has its own IPR, Esp, and Nuclear variables\n",
    "print('Same transaction, but country is Canada and Canada has its own IPR, Esp, and Nuclear variables.\\\n",
    " Predicted outcome: ', \n",
    "      experimental_outcomes[3])\n",
    "\n",
    "#Same as 2, but trade war variable is 1\n",
    "print('5. Same as 2., but trade war variable is active (1): ', \n",
    "      experimental_outcomes[4])\n",
    "\n",
    "#Same as 4, but trade war variable is 1\n",
    "print('6. Same as 4., but trade war variable is active (1): ', \n",
    "      experimental_outcomes[5])\n",
    "\n",
    "#Totally fabricated transaction 1\n",
    "print('7. China w/ same IPR and Esp. as used in logistic model; $750M Financial sector transcation: ', \n",
    "      experimental_outcomes[6])\n",
    "\n",
    "#Totally fabricated transaction 2\n",
    "print('8. China w/ same IPR and Esp. as used in logistic model; $400M Materials sector transcation: ', \n",
    "      experimental_outcomes[7])\n",
    "\n",
    "#Totally fabricated transaction 3\n",
    "print('China w/ same IPR and Esp. as used in logistic model; $1000M Financial sector transcation\\\n",
    "tradewar variable active: ', \n",
    "      experimental_outcomes[8])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
